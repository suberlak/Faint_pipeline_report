% mnras_template.tex
%
% LaTeX template for creating an MNRAS paper
%
% v3.0 released 14 May 2015
% (version numbers match those of mnras.cls)
%
% Copyright (C) Royal Astronomical Society 2015
% Authors:
% Keith T. Smith (Royal Astronomical Society)

% Change log
%
% v3.0 May 2015
%    Renamed to match the new package name
%    Version number matches mnras.cls
%    A few minor tweaks to wording
% v1.0 September 2013
%    Beta testing only - never publicly released
%    First version: a simple (ish) template for creating an MNRAS paper

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Basic setup. Most papers should leave these options alone.
\documentclass[fleqn,usenatbib]{mnras}  % a4paper,

% MNRAS is set in Times font. If you don't have this installed (most LaTeX
% installations will be fine) or prefer the old Computer Modern fonts, comment
% out the following line
%\usepackage{newtxtext,newtxmath}
%\usepackage{lmodern}
% Depending on your LaTeX fonts installation, you might get better results with one of these:
\usepackage{mathptmx}
%\usepackage{txfonts}


% Use vector fonts, so it zooms properly in on-screen viewing software
% Don't change these lines unless you know what you are doing
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
\usepackage{diagbox}

%%%%% AUTHORS - PLACE YOUR OWN PACKAGES HERE %%%%%

% Only include extra packages if you really need them. Common packages are:
\usepackage{graphicx}	% Including figure files
\usepackage{amsmath}	% Advanced maths commands
\usepackage{amssymb}	% Extra maths symbols
\usepackage{savesym}  % prevent symbol conflicts
\savesymbol{sf}
%\generate{%
%  \file{breqn.sty}{\nopreamble\from{breqn.dtx}{breqn.sty}}%
%}
%\usepackage{breqn} % automatic breaking equation 
%\usepackage{fancyvrb}
%\VerbatimFootnotes
\usepackage{cprotect}  % to allow verb in caption 
\DeclareMathOperator\erfc{erfc}
\DeclareMathOperator\erf{erf}
\DeclareMathOperator\cdf{cdf}
\DeclareMathOperator\sf{sf}
\DeclareMathOperator\isf{isf}
\DeclareMathOperator\ppf{ppf}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%% AUTHORS - PLACE YOUR OWN COMMANDS HERE %%%%%

% Please keep new commands to a minimum, and use \newcommand not \def to avoid
% overwriting existing commands. Example:
%\newcommand{\pcm}{\,cm$^{-2}$}	% per cm-squared

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%% TITLE PAGE %%%%%%%%%%%%%%%%%%%

% Title of the paper, and the short title which is used in the headers.
% Keep the title short and informative.
\title[Faint pipeline]{Bayesian pipeline to address the problem of faint flux measurement}

% The list of authors, and the short list which is used in the headers.
% If you need two or more lines of authors, add an extra line using \newauthor
\author[K. Suberlak et al.]{
Krzysztof Suberlak,$^{1}$\thanks{E-mail: suberlak@uw.edu}
\v{Z}eljko Ivezi\'c $^{1}$
\\
% List of institutions
$^{1}$Department of Astronomy, University of Washington, Seattle, WA, United States\\
}

% These dates will be filled out by the publisher
\date{Accepted XXX. Received YYY; in original form ZZZ}

% Enter the current year, for the copyright statements etc.
\pubyear{2017}

% Don't change these lines
\begin{document}
\label{firstpage}
\pagerange{\pageref{firstpage}--\pageref{lastpage}}
\maketitle

% Abstract of the paper
\begin{abstract}
A technical report to outline the methods used to reprocess forced photometry measurement below a certain small signal-to-noise ratio. By imposing a non-negative prior on faint and even negative fluxes we  are able to recover upper measurement limits and thus provide a more physical interpretation of the underlying brightness of the measured source at faint epochs. 
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%% BODY OF PAPER %%%%%%%%%%%%%%%%%%



\section{Introduction}
\label{sec:intro}

Many objects in the universe, from stellar to extragalactic scales, vary on timescales less than a few hundred years. Light curves carry a wealth of information allowing one to infer various physical properties of a planet or a galaxy. If a light curve is poorly sampled, the inferred  characteristics are less certain (see \cite{hogg1998} for review). Yet, since all  astronomical observations suffer from a detection threshold, a very faint variable object in some epochs may be undetectable. Forced photometry rescues the information from very faint epochs by performing a measurement in all epochs in a location from the co-added images. An inherent challenge to such set of measurements is an interpretation of noise-dominated flux. To circumvent this problem many studies apply a magnitude cutoff few magnitudes above the detection limit, which reduces the amount of available data. Indeed, in order to fully utilize information present in time-domain surveys, such as Large Scale Synoptic Telescope, Palomar Transient Factory, or Sloan Digital Sky Survey, and properly characterize faint variable objects, we need to properly handle the faint flux measurements. A new methodology would allow an unbiased  study of such faint variable objects, including quasars,  RR Lyrae,  Cepheids, and a wealth of other variable sources.  With the advent of precision  time-domain astronomy  surveys it is crucial to apply the best possible faint forced photometry algorithms and thus make full use of the  data.  


In this report we describe how faint measurements may arise, specifically as a result of performing forced photometry on background-subtracted data. We suggest a fully Bayesian approach to recalculating flux at each faint epoch, and provide example usage. 


\section{Faint Sources}
\label{sec:faint_sources}

%
%%%%%%%%%%%%%%%%% MOTIVATION %%%%%%%%%%%%%%%%%
%



Forced photometry in a background-subtracted epoch may yield unphysical, negative values. Such negative pixel value may originate from the variation of background across the image. If we model the background counts  as a Gaussian centered around the mean  $B_{0}$ :   $B-B_{0}  \sim  \mathcal{N}(0,\sigma_{B})$, then background in some parts of the image will be above, and in other parts below the mean value. After subtraction of the mean background value, regions with previously lower than average background will have negative pixel value.  This means that a forced photometry on a location where an object is undetected in single epoch may be measuring the background noise. Apart from creating low pixel values, background oscillation may also cause spurious detections where it is above the mean. For a large number of photons hitting the detector the width of the background noise distribution is  proportional to the square-root of counts: $\sigma_{B} \propto \sqrt {B}$. This yields a 1 in a million chance that a pixel has a background value larger than $5\sigma_{B}$.   Thus on a 16 megapixel CCD, like those used in SDSS, we anticipate  about  16 spuriously bright pixels  per CCD.  Therefore,  since forced photometry is affected by  the background noise, a special care must be taken of faint, noise-dominated measurements. 


%
%%%%%%%%%%%%%%%%% TREATMENT %%%%%%%%%%%%%%%%%
%

We remedy the unphysically low, even negative measurements for all 'faint' ($< 2\sigma$) sources and recalculate their fluxes. Each flux measurement can  be thought of as a  mean of the 'intrinsic' flux likelihood function $L(F)$. $L$ determines the probability that the flux has a value $F$. In our treatment we assume that $L$ is a Gaussian, and therefore its width corresponds to the measurement error :  $L(F) \sim \mathcal{N}(F,\sigma_{F})$. This means that bright sources with high signal-to-noise ratio have very narrow  $L$, and faint sources, dominated by noise, have $L$ with very wide tails.  Only for faint sources a significant portion of $L$ may be negative, corresponding to non-zero likelihood of flux being negative. This stands in conflict with our prior knowledge that no physical flux can be negative. We resolve this problem by recalculating single-epoch flux for all sources where $F < 2 \sigma_{F}$. We calculate for each epoch the mean of the truncated $L$, such that $L(F) = 0$ for $F<0$.  This shifts upward all measurements for faint epochs, and remedies the unphysicality of faint forced photometry fluxes.   

%
%%%%%%%%%%%%%%%%% CHOICE OF PRIOR %%%%%%%%%%%%%%%%%
%

In our treatment we are explicitly using a prior understanding of the flux behavior of any astrophysical object.  Without any further knowledge about the nature of the source, flat prior is the least informative Bayesian prior. Any additional information about the nature of object, and thus expected variability pattern,  could affect the choice of prior to be more specific. For instance,  consider a sinusoidal flux variability. If the flux of an object over many epochs is expected to vary in a sinusoidal fashion, i.e. $F(t) = F_{min}+ sin(t)$, the probability of a given  flux measurement is a cosine, ranging from $F_{min}$ to $F_{max}$. With that prior, without any measurement taken, the flux of the object is most likely  $(F_{min} + F_{max}) /  2$, i.e. at the peak of the cosine likelihood function. However, as soon as one measures $(F_{i},e_{i})$ from that source, the probability distribution of a flux at that epoch becomes a convolution of cosine prior information with the Gaussian curve of width $e_{i}$, centered on $F_{i}$ (assuming Gaussian errors). However, without any a-priori information about the variability pattern of the considered object, the least informative Bayesian prior we can impose is a flat one : $p(F)=0 $ for $F<0$, and $1$ elsewhere. Thus the posterior probability is 

\begin{equation}
p(F|data) \propto L(F|data) p(F)
\end{equation}


%
%%%%%%%%%%%%%%%%% WHAT WE CALCULATE %%%%%%%%%%%%%%%%%
%

To test the method we generate fiducial light curves (DRW / sinusoidal), with a uniform sampling ($N=100\div1000$). Based on the generated flux ($F_{true}$) we define the $5\sigma$ level as the robust 25-th percentile (or median) of the ensemble $F_{true}$ distribution :  $\sigma_{F} = (1/5)  F_{25 \%}$ (in reality, $\sigma$ increases for fainter observations, but this is a good approximation). 
\newline
We define $F_{obs} = F_{true} + F_{noise}$, where the Gaussian noise $F_{noise} = \sigma_{F}  \, \mathcal{N}(0,1)$ was added to each point. 
For a weak signal, defined as $F_{obs}^{i} < 2 \sigma{F}$, we consider $p(F)$  - a  Gaussian  likelihood associated with $i$-th measurement: $p_{i}(F) = \mathcal{N}(\mu=F_{obs}^{i}, \sigma=\sigma_{F})$. Each measurement $F_{obs}$ is a mean of this likelihood: $F_{obs} = \langle p_{i}(F) \rangle$. We call it $p(F)$  for short : 



For each epoch, based on the raw forced photometry measurement, we calculate new descriptors of faint fluxes. We define a faint measurement by $F_{i} < 2 \sigma{F_{i}}$, i.e. where the flux is less than twice the flux error. We assume that the flux is the mean of the Gaussian likelihood  $p_{i}(F) = \mathcal{N}(\mu=F_{i}, \sigma=\sigma_{F_{i}})$ : 
\begin{equation}
p(F) = \frac{1}{\sqrt{2  \pi \sigma_{F}^{2}}} \exp{ \left(-\frac{(F-\mu)^{2}}{2\sigma_{F}^{2}}\right)}
\end{equation}

so that $F_{i} =\langle p(F) \rangle $.  For faint measurements we truncate the negative part of $p(F)$, and recalculate the mean, median, rms, and $2 \sigma$ level. Thus the mean is  


\begin{equation}
F_{mean} = \frac{\int _{0} ^ {\infty}{F p(F) dF}}{\int _{0} ^ {\infty}{p(F) dF}}
\end{equation} 
where we normalized the truncated Gaussian likelihood.
 
We define the median as  

\begin{equation}
\int _{0} ^ {F_{median}} {p(F) dF} = \int _{F_{median}} ^ {\infty} {p(F) dF}
\end{equation} 

The rms level is

\begin{equation}
F_{rms}^{2} = \frac{\int _{0} ^ {\infty}{(F-F_{mean})^{2} p(F) dF}}{\int _{0} ^ {\infty}{p(F) dF}} 
\end{equation}

Finally, since for a Gaussian distribution the area contained between $\mu \pm \sigma$ is $95.5 \%$ of the total area under the curve, for the truncated Gaussian we define the  $2 \sigma$ level as:

\begin{equation}
\int _{F_{2 \sigma}} ^{\infty} {p(F)dF} = 0.05 * \int _{0} ^{\infty} {p(F) dF} 
\end{equation}

Both for median and for the $2\sigma$ level the normalization cancels out (see Sec.~\ref{sec:analytic})


\section{Treatment of faint sources}
\label{sec:analytic}

In our calculations we used the  \verb|scipy| implementation of 
the following often used integrals of Gaussian distributions : 

- cumulative density function, that is an area under the Gaussian distribution from $-\infty$ to $x_{0}$ :

\begin{equation}
\cdf(x_{0}) = \int_{-\infty}^{x_{0}}{\mathcal{N}(\mu,\sigma)dx} = \int_{-\infty}^{x_{0}}{\frac{\exp{(x-\mu)^{2} / 2\sigma^{2}}}{\sqrt{2\pi\sigma^{2}}} dx}
\end{equation}

- point percent function , that is an inverse of the cumulative density function:  if  $A = \cdf(x_{0})$, then  $x_{0} = \ppf(A)$

- survival function (also known  as the complementary cumulative distribution function), that is an area under a Gaussian distribution from $x_{0}$ to $\infty$

\begin{multline}
\sf(x_{0}) =  \int_{x_{0}}^{\infty}{\mathcal{N}(\mu,\sigma)dx} =  \int_{-\infty}^{\infty}{\mathcal{N}(\mu,\sigma)dx} -  \int_{-\infty}^{x_{0}}{\mathcal{N}(\mu,\sigma)dx} = \\
1 - \cdf(x_{0})
\end{multline}

In our faint flux treatment  we assume that each flux measurement has an associated Gaussian likelihood, and that the width and mean of the likelihood correspond 
to the measured flux and the measurement error respectively. 

For a source where signal-to-noise < 2 (in our case, ratio of  flux to error), we remove the negative portion of the likelihood, since there is no physical likelihood that a flux would be negative.
Thus for mean, we integrate from $0$ instead of $-\infty$ : 


\begin{equation}
F_{mean} = \frac{\int _{0} ^ {\infty}{F p(F) dF}}{\int _{0} ^ {\infty}{p(F) dF}} = I_{0} / I_{1}
\end{equation}

where we need to normalize by the integral over the positive part of the Gaussian likelihood. 

We evaluate 

\begin{multline}
I_{0}= \int _{0} ^ {\infty} {\frac{F}{\sqrt{2\pi\sigma_{F}^{2}}} \exp{\left(-\frac{(F-F_{obs})^{2}}{2\sigma_{F}^{2}}\right)} }dF = \\  \frac{\sigma_{F}}{\sqrt{2 \pi}} \exp{\left(- \frac{F_{obs}^{2}}{2\sigma_{F}^{2}} \right)} + F_{obs} \sf{\left( \frac{-F_{obs}}{\sigma_{F}}\right)}
\end{multline}

and 

\begin{equation}
I_{1} = \int _{0} ^ {\infty}{ p(F) dF} = \int _{0} ^ {\infty} {\frac{\exp{\left(-\frac{(F-F_{obs})^{2}}{2\sigma_{F}^{2}}\right)} }{\sqrt{2\pi\sigma_{F}^{2}}} }dF = \sf{(-F_{obs} / \sigma_{F})}
\end{equation}

so that 
\begin{equation}
x_{mean} = \frac{\exp{(- x_{obs}^{2} / 2 )} }{\sf{(-x_{obs})}\sqrt{2 \pi}} + x_{obs} 
\end{equation}

where we scaled $F_{obs}$ by  $\sigma_F$  (i.e. $F_{mean} = x_{mean} \cdot \sigma_{F}$). 



\bigskip

To find the median and the $2\sigma$ level we transform from $F$ space to $x$ space , scaling by  $\sigma_{F}$, so that $x = F / \sigma_{F}$ , and thus the likelihood $p(x) \sim \mathcal{N}(x_{obs},1)$ is :
\begin{equation}
p(x) = \frac{1}{\sqrt{2  \pi }} \exp{ \left(-\frac{(x-x_{obs})^{2}}{2}\right)}
\end{equation}

We  then transform from $x$ to $z$ space, with  a translation by $x_{obs} = F_{obs} / \sigma_{F}$ :  $z = x - x_{obs}$  , so that now  $p(z) \sim \mathcal{N}(0,1)$:
\begin{equation}
p(z) = \frac{1}{\sqrt{2  \pi }} \exp{ \left(-\frac{z^2}{2}\right)}
\end{equation}



In $z$-space, the median from 

\begin{equation}
\int_{0}^{x_{med}} {p(x)dx} = \int_{x_{med}}^{\infty} {p(x)dx}
\end{equation}
 
becomes 

\begin{equation}
\int_{x_{0}}^{z_{med}}{p(z)dz} = \int_{z_{med}}^{\infty}{p(z)dz}
\end{equation}

with  $x_{0}=-x_{obs}$

\bigskip

We evaluate $z_{med}$ analytically  - the right hand side is the survival function  : 

\begin{equation}
\int_{z_{med}}^{\infty}{p(z)dz} = \sf(z_{med})
\end{equation}

and the left hand side, assuming that the median $z_{med} > x_{0}$, is :

\begin{multline}
\int_{x_{0}}^{z_{med}}{p(z)dz} = \int_{-\infty}^{z_{med}}{p(z)dz} - \int_{-\infty}^{x_{0}}{p(z)dz} = \cdf(z_{med}) - \cdf(x_{0})
\end{multline}

Rearranging, and using the percent point function ($\ppf$)  we find:

\begin{equation}
z_{med} = \ppf \left( \frac{1+\cdf(x_{0})}{2} \right)
\end{equation}

and transforming back to $F$ space: 

\begin{equation}
F_{med} = F_{obs} + \sigma_{F} \, \ppf \left( \frac{1+\cdf(x_{0})}{2} \right)
\end{equation}

with $x_{0}$ and $x_{obs}$ as above.  We also normalize this expression by $\int _{0} ^ {\infty}{ p(F) dF}$ and $\sigma_{F}$:

\begin{equation}
x_{med}^{norm} = x_{obs}
\end{equation}


\bigskip

In $z$  space , the $2\sigma$ areas  $A$ and $B$ are :

$\text{A} = \sf(x_{0})$ and $\text{B} = \sf(z_{B})$, so to find  $z_{B}$ we use the  inverse survival function $\isf$ : $z_{B} = \isf(0.05 \text{A})$. Thus transforming back to $F$-space we have:

\begin{equation}
F_{2\sigma} = F_{obs} + \sigma_{F} \left(\, \isf (\, 0.05 \sf (x_{0})  \right)
\end{equation}

\bigskip

We also find the root-mean-square:

\begin{equation}
F_{rms}^{2} = \frac{\int _{0} ^ {\infty}{(F-F_{mean})^{2} p(F) dF}}{\int _{0} ^ {\infty}{p(F) dF}} = I_{0} / I_{1}
\end{equation}

this can be evaluated by numerical integration, scaling by $\sigma_{F}$, so that $x_{mean} = F_{mean} / \sigma_{F}$, $x_{obs} = F_{obs} / \sigma_{F}$ : 

\begin{equation}
F_{rms}^{2} = \frac{\sigma_{F}^{2} \int_{0}^{\infty} {(x-x_{mean})^{2} exp(-(x-x_{obs})^{2} / 2 ) dx }}  {\int_{0}^{\infty} {exp(-(x-x_{obs})^{2} / 2 ) dx }}
\end{equation}

We derived analytical expression for rms :
\begin{equation}
x_{rms} = \left(\frac{I_{0}}{I_{1} \sigma_{F}^{2}}\right)^{1/2}
\end{equation}

where $I_{1}$ is our normalization , as in calculation of $F_{mean}$, and as 


\begin{equation}
\frac{I_{0}}{ \sigma_{F}^{2}} = \frac{1}{2} \erf\left(\frac{x_{obs}}{\sqrt{2}}\right) + \frac{1}{\sqrt{2\pi}} e^{(-x_{obs}^{2} / 2)} (2 \Delta x - x_{obs}) + (\Delta x)^{2} \sf(-x_{obs})
\end{equation}
with  $\Delta x = x_{obs} - x_{mean}$



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%

% The best way to enter references is to use BibTeX:

\bibliographystyle{mnras}
\bibliography{references} % if your bibtex file is called example.bib

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Don't change these lines
\bsp	% typesetting comment
\label{lastpage}
\end{document}

% End of mnras_template.tex
